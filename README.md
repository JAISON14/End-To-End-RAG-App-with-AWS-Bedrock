# End to End LLM RAG App with AWS Bedrock

This project demonstrates the power of Large Language Models (LLMs) for processing and understanding content from PDF documents. It leverages AWS Bedrock for generating embeddings, FAISS for efficient vector indexing, and supports querying with state-of-the-art models like Claude and Llama2.

## Features
Data Ingestion: Load and preprocess PDF documents.

Vector Embedding: Generate embeddings for document content using Titan Embeddings Model.

Vector Store: Index embeddings with FAISS for efficient similarity search.

LLM Integration: Use Claude and Llama2 models for answering queries based on document content.

Streamlit Interface: A user-friendly web interface for interacting with the LLM system.
